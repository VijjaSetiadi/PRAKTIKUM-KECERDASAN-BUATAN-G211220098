{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5IMxW90FqSY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train_x = train_x.astype('float32') / 255.\n",
        "test_x = test_x.astype('float32') / 255.\n",
        "\n",
        "train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
        "test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
        "\n",
        "train_y = to_categorical( train_y )\n",
        "test_y = to_categorical( test_y )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGT0e9M-G0NV",
        "outputId": "3a9b196d-5195-4d5d-f92b-6f6084409822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " zero_padding2d_3 (ZeroPadd  (None, 32, 32, 1)         0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        416       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 3, 3, 32)          4640      \n",
            "                                                                 \n",
            " zero_padding2d_4 (ZeroPadd  (None, 5, 5, 32)          0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 3, 3, 64)          18496     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               147712    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 188362 (735.79 KB)\n",
            "Trainable params: 188362 (735.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction Layer\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv_layer = ZeroPadding2D(padding=(2,2))(inputs)\n",
        "conv_layer = Conv2D(16, (5, 5), strides=(3,3), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = ZeroPadding2D(padding=(1,1))(conv_layer)\n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "\n",
        "# Flatten feature map to Vector with 576 element.\n",
        "flatten = Flatten()(conv_layer)\n",
        "\n",
        "# Fully Connected Layer\n",
        "fc_layer = Dense(256, activation='relu')(flatten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "outputs = Dense(10, activation='softmax')(fc_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Adam Optimizer and Cross Entropy Loss\n",
        "adam = Adam(lr=0.0001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print Model Summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrRvktTBG72Z",
        "outputId": "dc517b8e-1081-46dc-9468-9f0d7801f794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 14s 50ms/step - loss: 0.7814 - accuracy: 0.7071 - val_loss: 0.5689 - val_accuracy: 0.7936\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.5016 - accuracy: 0.8134 - val_loss: 0.4674 - val_accuracy: 0.8351\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.4223 - accuracy: 0.8439 - val_loss: 0.4093 - val_accuracy: 0.8538\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.3729 - accuracy: 0.8635 - val_loss: 0.3898 - val_accuracy: 0.8593\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.3433 - accuracy: 0.8739 - val_loss: 0.3647 - val_accuracy: 0.8659\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3245 - accuracy: 0.8804 - val_loss: 0.3477 - val_accuracy: 0.8731\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.3060 - accuracy: 0.8867 - val_loss: 0.3515 - val_accuracy: 0.8724\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.2914 - accuracy: 0.8924 - val_loss: 0.3308 - val_accuracy: 0.8836\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.2793 - accuracy: 0.8971 - val_loss: 0.3307 - val_accuracy: 0.8799\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.2712 - accuracy: 0.8988 - val_loss: 0.3260 - val_accuracy: 0.8833\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.2589 - accuracy: 0.9024 - val_loss: 0.3285 - val_accuracy: 0.8826\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.2489 - accuracy: 0.9065 - val_loss: 0.3070 - val_accuracy: 0.8904\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2411 - accuracy: 0.9101 - val_loss: 0.3076 - val_accuracy: 0.8932\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2323 - accuracy: 0.9123 - val_loss: 0.3083 - val_accuracy: 0.8897\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.2262 - accuracy: 0.9149 - val_loss: 0.3067 - val_accuracy: 0.8885\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.2169 - accuracy: 0.9171 - val_loss: 0.2953 - val_accuracy: 0.8930\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.2071 - accuracy: 0.9222 - val_loss: 0.2967 - val_accuracy: 0.8949\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.2022 - accuracy: 0.9245 - val_loss: 0.2948 - val_accuracy: 0.8957\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.1917 - accuracy: 0.9279 - val_loss: 0.3045 - val_accuracy: 0.8950\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.1870 - accuracy: 0.9293 - val_loss: 0.3010 - val_accuracy: 0.8946\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1783 - accuracy: 0.9318 - val_loss: 0.3048 - val_accuracy: 0.8984\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.1723 - accuracy: 0.9341 - val_loss: 0.3147 - val_accuracy: 0.8937\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.1641 - accuracy: 0.9374 - val_loss: 0.3278 - val_accuracy: 0.8947\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1570 - accuracy: 0.9399 - val_loss: 0.3108 - val_accuracy: 0.8941\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.1528 - accuracy: 0.9410 - val_loss: 0.3134 - val_accuracy: 0.8956\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1457 - accuracy: 0.9445 - val_loss: 0.3423 - val_accuracy: 0.8901\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1355 - accuracy: 0.9488 - val_loss: 0.3351 - val_accuracy: 0.8961\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.1295 - accuracy: 0.9508 - val_loss: 0.3496 - val_accuracy: 0.8957\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1223 - accuracy: 0.9547 - val_loss: 0.3760 - val_accuracy: 0.8887\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.1197 - accuracy: 0.9549 - val_loss: 0.3644 - val_accuracy: 0.8956\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1109 - accuracy: 0.9582 - val_loss: 0.3824 - val_accuracy: 0.8921\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.1042 - accuracy: 0.9609 - val_loss: 0.3880 - val_accuracy: 0.8939\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0983 - accuracy: 0.9632 - val_loss: 0.3931 - val_accuracy: 0.8891\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0936 - accuracy: 0.9648 - val_loss: 0.3991 - val_accuracy: 0.8929\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0886 - accuracy: 0.9658 - val_loss: 0.4082 - val_accuracy: 0.8934\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0823 - accuracy: 0.9692 - val_loss: 0.4257 - val_accuracy: 0.8950\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0796 - accuracy: 0.9698 - val_loss: 0.4520 - val_accuracy: 0.8946\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0714 - accuracy: 0.9728 - val_loss: 0.4415 - val_accuracy: 0.8949\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.5029 - val_accuracy: 0.8890\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0710 - accuracy: 0.9727 - val_loss: 0.4800 - val_accuracy: 0.8927\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0652 - accuracy: 0.9752 - val_loss: 0.5116 - val_accuracy: 0.8914\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0653 - accuracy: 0.9749 - val_loss: 0.4716 - val_accuracy: 0.8953\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.5382 - val_accuracy: 0.8918\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0539 - accuracy: 0.9803 - val_loss: 0.5496 - val_accuracy: 0.8923\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0504 - accuracy: 0.9814 - val_loss: 0.5563 - val_accuracy: 0.8936\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.5592 - val_accuracy: 0.8910\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0512 - accuracy: 0.9807 - val_loss: 0.5747 - val_accuracy: 0.8931\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0521 - accuracy: 0.9797 - val_loss: 0.5603 - val_accuracy: 0.8919\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0423 - accuracy: 0.9848 - val_loss: 0.5745 - val_accuracy: 0.8947\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0438 - accuracy: 0.9835 - val_loss: 0.6017 - val_accuracy: 0.8950\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0353 - accuracy: 0.9869 - val_loss: 0.6320 - val_accuracy: 0.8930\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0358 - accuracy: 0.9864 - val_loss: 0.6286 - val_accuracy: 0.8921\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0495 - accuracy: 0.9814 - val_loss: 0.6533 - val_accuracy: 0.8903\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0412 - accuracy: 0.9845 - val_loss: 0.6567 - val_accuracy: 0.8921\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.6979 - val_accuracy: 0.8945\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0412 - accuracy: 0.9847 - val_loss: 0.6792 - val_accuracy: 0.8897\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.6728 - val_accuracy: 0.8941\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.7281 - val_accuracy: 0.8885\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0356 - accuracy: 0.9865 - val_loss: 0.6969 - val_accuracy: 0.8924\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.7544 - val_accuracy: 0.8928\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.7253 - val_accuracy: 0.8906\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.7236 - val_accuracy: 0.8890\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.7850 - val_accuracy: 0.8896\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.8120 - val_accuracy: 0.8795\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0419 - accuracy: 0.9847 - val_loss: 0.7054 - val_accuracy: 0.8905\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.7538 - val_accuracy: 0.8921\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.7856 - val_accuracy: 0.8885\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.7929 - val_accuracy: 0.8922\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.7861 - val_accuracy: 0.8923\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.8039 - val_accuracy: 0.8875\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.7930 - val_accuracy: 0.8894\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.8100 - val_accuracy: 0.8896\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.8384 - val_accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.8408 - val_accuracy: 0.8945\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.8793 - val_accuracy: 0.8935\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.8546 - val_accuracy: 0.8878\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.8525 - val_accuracy: 0.8846\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.8628 - val_accuracy: 0.8866\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0249 - accuracy: 0.9910 - val_loss: 0.8509 - val_accuracy: 0.8901\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.9182 - val_accuracy: 0.8908\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.8806 - val_accuracy: 0.8912\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.8697 - val_accuracy: 0.8916\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.9138 - val_accuracy: 0.8878\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.8820 - val_accuracy: 0.8885\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.9137 - val_accuracy: 0.8905\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.9297 - val_accuracy: 0.8932\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.8836 - val_accuracy: 0.8871\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 0.9281 - val_accuracy: 0.8905\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.9184 - val_accuracy: 0.8887\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.9124 - val_accuracy: 0.8871\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.9058 - val_accuracy: 0.8889\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.9680 - val_accuracy: 0.8827\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.9503 - val_accuracy: 0.8849\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.8765 - val_accuracy: 0.8892\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.9165 - val_accuracy: 0.8928\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 1.0245 - val_accuracy: 0.8881\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.9396 - val_accuracy: 0.8862\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.9095 - val_accuracy: 0.8917\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.9787 - val_accuracy: 0.8905\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.9878 - val_accuracy: 0.8863\n"
          ]
        }
      ],
      "source": [
        "# Use TensorBoard\n",
        "callbacks = TensorBoard(log_dir='./Graph')\n",
        "\n",
        "# Train for 100 Epochs and use TensorBoard Callback\n",
        "model.fit(train_x, train_y, batch_size=256, epochs=100, verbose=1, validation_data=(test_x, test_y), callbacks=[callbacks])\n",
        "\n",
        "# Save Weights\n",
        "model.save_weights('weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPmLxNq8G_sR"
      },
      "outputs": [],
      "source": [
        "# Feature Extraction Layer\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv_layer = ZeroPadding2D(padding=(2,2))(inputs)\n",
        "conv_layer = Conv2D(16, (5, 5), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "\n",
        "# Flatten feature map to Vector with 576 element.\n",
        "flatten = Flatten()(conv_layer)\n",
        "\n",
        "# Fully Connected Layer\n",
        "fc_layer = Dense(256, activation='relu')(flatten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "outputs = Dense(10, activation='softmax')(fc_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbQPXdeHHL1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a71404e-fbe1-498e-c667-b8876e4e8a2b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " zero_padding2d_6 (ZeroPadd  (None, 32, 32, 1)         0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 16)        416       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 12, 12, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 10, 10, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 3, 3, 64)          18496     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 197610 (771.91 KB)\n",
            "Trainable params: 197610 (771.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 48s 199ms/step - loss: 0.7392 - accuracy: 0.7258 - val_loss: 0.4978 - val_accuracy: 0.8141\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 48s 205ms/step - loss: 0.4397 - accuracy: 0.8381 - val_loss: 0.3907 - val_accuracy: 0.8595\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 50s 214ms/step - loss: 0.3535 - accuracy: 0.8719 - val_loss: 0.3475 - val_accuracy: 0.8736\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 48s 204ms/step - loss: 0.3119 - accuracy: 0.8856 - val_loss: 0.3530 - val_accuracy: 0.8758\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 48s 204ms/step - loss: 0.2866 - accuracy: 0.8954 - val_loss: 0.3099 - val_accuracy: 0.8880\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 49s 209ms/step - loss: 0.2655 - accuracy: 0.9029 - val_loss: 0.2958 - val_accuracy: 0.8944\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 45s 190ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.2843 - val_accuracy: 0.8965\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 47s 202ms/step - loss: 0.2365 - accuracy: 0.9137 - val_loss: 0.2810 - val_accuracy: 0.8972\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 45s 193ms/step - loss: 0.2236 - accuracy: 0.9173 - val_loss: 0.2724 - val_accuracy: 0.9024\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 46s 196ms/step - loss: 0.2138 - accuracy: 0.9218 - val_loss: 0.2637 - val_accuracy: 0.9041\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 46s 195ms/step - loss: 0.2014 - accuracy: 0.9261 - val_loss: 0.2709 - val_accuracy: 0.9018\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 45s 193ms/step - loss: 0.1922 - accuracy: 0.9297 - val_loss: 0.2624 - val_accuracy: 0.9097\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 47s 198ms/step - loss: 0.1832 - accuracy: 0.9326 - val_loss: 0.2580 - val_accuracy: 0.9079\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 47s 198ms/step - loss: 0.1732 - accuracy: 0.9370 - val_loss: 0.2555 - val_accuracy: 0.9090\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 47s 198ms/step - loss: 0.1645 - accuracy: 0.9387 - val_loss: 0.2492 - val_accuracy: 0.9123\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 45s 191ms/step - loss: 0.1527 - accuracy: 0.9439 - val_loss: 0.2625 - val_accuracy: 0.9124\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 45s 193ms/step - loss: 0.1468 - accuracy: 0.9458 - val_loss: 0.2749 - val_accuracy: 0.9100\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 45s 194ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.2697 - val_accuracy: 0.9118\n",
            "Epoch 19/100\n",
            " 68/235 [=======>......................] - ETA: 31s - loss: 0.1293 - accuracy: 0.9507"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train_x = train_x.astype('float32') / 255.\n",
        "test_x = test_x.astype('float32') / 255.\n",
        "\n",
        "train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
        "test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
        "\n",
        "train_y = to_categorical( train_y )\n",
        "test_y = to_categorical( test_y )\n",
        "\n",
        "# Feature Extraction Layer\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv_layer = ZeroPadding2D(padding=(2,2))(inputs)\n",
        "conv_layer = Conv2D(16, (5, 5), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "\n",
        "# Flatten feature map to Vector with 576 element.\n",
        "flatten = Flatten()(conv_layer)\n",
        "\n",
        "# Fully Connected Layer\n",
        "fc_layer = Dense(256, activation='relu')(flatten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "outputs = Dense(10, activation='softmax')(fc_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Adam Optimizer and Cross Entropy Loss\n",
        "adam = Adam(lr=0.0001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print Model Summary\n",
        "print(model.summary())\n",
        "\n",
        "# Use TensorBoard\n",
        "callbacks = TensorBoard(log_dir='./Graph')\n",
        "\n",
        "# Train for 100 Epochs and use TensorBoard Callback\n",
        "model.fit(train_x, train_y, batch_size=256, epochs=100, verbose=1, validation_data=(test_x, test_y), callbacks=[callbacks])\n",
        "\n",
        "# Save Weights\n",
        "model.save_weights('weights.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}